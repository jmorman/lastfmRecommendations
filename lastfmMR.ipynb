{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#MRCalculateSimilarity.py takes about 40 sec for 50k rows on my machine\n",
      "#500k ~9 min"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Testing new way of computing user_average s\n",
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import seaborn as sns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Prepare entire dataset for MR\n",
      "df = pd.read_csv(\"./lastfm-dataset-360K/usersha1-artmbid-artname-plays.tsv\", nrows=None, sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "start_time = time.time()\n",
      "df['log_listens'] = df['num_plays'].map(lambda x: np.log(x))\n",
      "print \"Took \" + str(time.time() - start_time) + \" seconds\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Took 21.5134930611 seconds\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Faster way of computing user_average\n",
      "#Takes advantage of the fact that dataset is already grouped by users\n",
      "\n",
      "#Takes ~65 sec with 100k, 353 sec with 500k (linear, not quadratic!)\n",
      "#For the whole ~17.6 million, 10538 sec (~176 min)\n",
      "\n",
      "#Compare with method in lastfmSmallRec, which takes an amount of time that grows quadratically in the number of rows\n",
      "#and takes 228 minutes for 500k rows\n",
      "\n",
      "start_time = time.time()\n",
      "\n",
      "user_averages = []\n",
      "user_id = df.iloc[[0]].user_id.item()\n",
      "user_num_artists = 0\n",
      "user_sum_loglistens = 0\n",
      "for row in range(len(df)):\n",
      "    if (df.iloc[[row]].user_id.item() != user_id):\n",
      "        user_id = df.iloc[[row]].user_id.item()\n",
      "        user_averages.extend([user_sum_loglistens/user_num_artists] * user_num_artists)\n",
      "        user_num_artists = 0\n",
      "        user_sum_loglistens = 0\n",
      "    user_num_artists = user_num_artists + 1\n",
      "    user_sum_loglistens = user_sum_loglistens + df.iloc[[row]].log_listens.item()\n",
      "    \n",
      "#For last user in table\n",
      "user_id = df.iloc[[row]].user_id.item()\n",
      "user_averages.extend([user_sum_loglistens/user_num_artists] * user_num_artists)\n",
      "    \n",
      "print \"Took \" + str(time.time() - start_time) + \" seconds\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Took 10538.0463979 seconds\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#(For 100k)\n",
      "df['user_avg2'] = user_averages\n",
      "#Result is the same (to within rounding error)\n",
      "differences = df['user_avg'] - df['user_avg2']\n",
      "print sorted(differences.unique())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[-4.4408920985006262e-15, -3.5527136788005009e-15, -3.1086244689504383e-15, -2.6645352591003757e-15, -2.2204460492503131e-15, -1.7763568394002505e-15, -1.5543122344752192e-15, -1.3322676295501878e-15, -1.1102230246251565e-15, -8.8817841970012523e-16, -7.7715611723760958e-16, -6.6613381477509392e-16, -5.5511151231257827e-16, -4.4408920985006262e-16, -2.2204460492503131e-16, -1.1102230246251565e-16, -2.7755575615628914e-17, 0.0, 1.1102230246251565e-16, 2.2204460492503131e-16, 3.3306690738754696e-16, 4.4408920985006262e-16, 6.6613381477509392e-16, 7.7715611723760958e-16, 8.8817841970012523e-16, 9.9920072216264089e-16, 1.1102230246251565e-15, 1.3322676295501878e-15, 1.5543122344752192e-15, 1.7763568394002505e-15, 2.2204460492503131e-15, 2.6645352591003757e-15, 3.1086244689504383e-15, 3.5527136788005009e-15, 5.3290705182007514e-15]\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['user_avg'] = user_averages"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Only use artists with mbids, and throw out artist names\n",
      "#Lose about 200k rows by taking out artists w/o MBIDs\n",
      "with_mbid_df = df[df.artist_id.map(lambda x: isinstance(x, str))]\n",
      "print len(with_mbid_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "17309518\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print with_mbid_df.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Index([u'user_id', u'artist_id', u'artist_name', u'num_plays', u'log_listens', u'user_avg'], dtype='object')\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#No header and index to facilitate use with MapReduce\n",
      "with_mbid_df[['user_id', 'artist_id', 'log_listens', 'user_avg']].to_csv(\"17.3m_with_added_cols.csv\", \n",
      "                                                                            index=False, header=False)\n",
      "with_mbid_df[:1000000][['user_id', 'artist_id', 'log_listens', 'user_avg']].to_csv(\"1m_with_added_cols.csv\", \n",
      "                                                                            index=False, header=False)\n",
      "with_mbid_df[:500000][['user_id', 'artist_id', 'log_listens', 'user_avg']].to_csv(\"500k_with_added_cols.csv\", \n",
      "                                                                            index=False, header=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Some mrjob incantations\n",
      "##Create job flow: \n",
      "##mrjob create-job-flow --ec2-instance-type=m1.large --num-ec2-instances=5\n",
      "##Small test \n",
      "##python MRCalculateSimilarity.py -r emr --emr-job-flow-id=j-2URV8053VTA5M 10k_with_added_cols.csv > outputs/EMR_10k_n.out\n",
      "##Full dataset, regularize later, minimum 3 common, exclude negative scores\n",
      "##python MRCalculateSimilarityTrimmed.py -r emr --emr-job-flow-id=j-2URV8053VTA5M s3://veryuniquebucketname/17.3m_with_added_cols.csv > outputs/EMR_full_n.out\n",
      "##Full dataset, regularized (5), minimum 3 common, exclude negative scores\n",
      "##python MRCalculateSimilarityTrimmedB.py -r emr --emr-job-flow-id=j-2URV8053VTA5M s3://veryuniquebucketname/17.3m_with_added_cols.csv > outputs/EMR_full_b.out\n",
      "##Clean up\n",
      "##mrjob terminate-job-flow j-2URV8053VTA5M"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "There was an issue when trying to calculate similarity for the whole dataset. Some of the user_ids appear as dates for some reason. The first case is at row 15,060,986, which is why the issue only appeared when working with the whole dataset.\n",
      "\n",
      "Example:\n",
      "\n",
      "dec256dc552b2c6f2834b4f8a0e32fe93f3db306,802347f6-3630-4fa2-9118-e1e73347c575,1.6094379124341003,2.287901112964663\n",
      "dec256dc552b2c6f2834b4f8a0e32fe93f3db306,f3569bd0-2acb-41de-9fec-409c067f1abc,1.6094379124341003,2.287901112964663\n",
      "\"dec 27, 2008\",fee8e811-a2dc-4c09-8484-3c2aca38c3f9,6.1092475827643655,4.806270876752255\n",
      "\"dec 27, 2008\",ffa25bb8-a082-4b47-aa4c-9ef48df98dc6,6.003887067106539,4.806270876752255\n",
      "\"dec 27, 2008\",18191eea-369f-42e8-96ab-c1c24e4d0011,5.8377304471659395,4.806270876752255\n",
      "\n",
      "Rare enough that I was able to just manually delete them, bringing the final row count to 17309430"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#EMR results for running MRCalculateSimilarity.py (similar times for the other scripts):\n",
      "#Using 5 m1.large instances: 451s for 500k, 709s for 1m\n",
      "#Using 10 m1.large instance: 4077s for 17.3m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}